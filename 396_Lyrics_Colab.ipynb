{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "396 Lyrics Colab",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "ce1cf71e-8be5-4837-8df9-7d87d6268888"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmkWnPmDYE2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aca9477-2d3b-4129-c583-4dcebeebc3ab"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/lyrics2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "541045ce-489c-4099-a5f8-55566d925284"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 239Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 96.0Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 216Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:17, 81.0Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 231Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 92.3Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 18.5Mit/s]                                                      \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"nursery_rhymes.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "e68c4558-4f2e-4c67-bd5b-87c16e8f26ba"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=(\"dataset/\" + file_name),\n",
        "              model_name='355M',\n",
        "              steps=2000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run6',\n",
        "              print_every=10,\n",
        "              sample_every=500,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 14748 tokens\n",
            "Training...\n",
            "[10 | 17.84] loss=2.64 avg=2.64\n",
            "[20 | 26.67] loss=2.51 avg=2.58\n",
            "[30 | 35.50] loss=1.12 avg=2.09\n",
            "[40 | 44.33] loss=0.58 avg=1.70\n",
            "[50 | 53.16] loss=0.06 avg=1.37\n",
            "[60 | 61.98] loss=0.05 avg=1.14\n",
            "[70 | 70.81] loss=0.06 avg=0.98\n",
            "[80 | 79.64] loss=0.02 avg=0.86\n",
            "[90 | 88.47] loss=0.01 avg=0.76\n",
            "[100 | 97.29] loss=0.07 avg=0.69\n",
            "[110 | 106.11] loss=0.02 avg=0.62\n",
            "[120 | 114.93] loss=0.02 avg=0.57\n",
            "[130 | 123.76] loss=0.03 avg=0.53\n",
            "[140 | 132.59] loss=0.02 avg=0.49\n",
            "[150 | 141.42] loss=0.05 avg=0.46\n",
            "[160 | 150.23] loss=0.03 avg=0.43\n",
            "[170 | 159.06] loss=0.04 avg=0.40\n",
            "[180 | 167.90] loss=0.03 avg=0.38\n",
            "[190 | 176.72] loss=0.07 avg=0.36\n",
            "[200 | 185.55] loss=0.01 avg=0.34\n",
            "[210 | 194.38] loss=0.04 avg=0.33\n",
            "[220 | 203.20] loss=0.02 avg=0.31\n",
            "[230 | 212.02] loss=0.06 avg=0.30\n",
            "[240 | 220.85] loss=0.03 avg=0.29\n",
            "[250 | 229.68] loss=0.03 avg=0.28\n",
            "[260 | 238.51] loss=0.02 avg=0.26\n",
            "[270 | 247.33] loss=0.01 avg=0.25\n",
            "[280 | 256.15] loss=0.02 avg=0.24\n",
            "[290 | 264.98] loss=0.01 avg=0.23\n",
            "[300 | 273.82] loss=0.02 avg=0.23\n",
            "[310 | 282.66] loss=0.03 avg=0.22\n",
            "[320 | 291.49] loss=0.02 avg=0.21\n",
            "[330 | 300.30] loss=0.04 avg=0.21\n",
            "[340 | 309.14] loss=0.03 avg=0.20\n",
            "[350 | 317.96] loss=0.03 avg=0.19\n",
            "[360 | 326.78] loss=0.01 avg=0.19\n",
            "[370 | 335.60] loss=0.02 avg=0.18\n",
            "[380 | 344.43] loss=0.01 avg=0.18\n",
            "[390 | 353.25] loss=0.05 avg=0.17\n",
            "[400 | 362.07] loss=0.03 avg=0.17\n",
            "[410 | 370.90] loss=0.01 avg=0.16\n",
            "[420 | 379.72] loss=0.04 avg=0.16\n",
            "[430 | 388.54] loss=0.02 avg=0.16\n",
            "[440 | 397.37] loss=0.01 avg=0.15\n",
            "[450 | 406.19] loss=0.02 avg=0.15\n",
            "[460 | 415.02] loss=0.02 avg=0.14\n",
            "[470 | 423.84] loss=0.01 avg=0.14\n",
            "[480 | 432.66] loss=0.01 avg=0.14\n",
            "[490 | 441.49] loss=0.04 avg=0.14\n",
            "[500 | 450.32] loss=0.04 avg=0.13\n",
            "Saving checkpoint/lmm-1/model-500\n",
            "======== SAMPLE 1 ========\n",
            " headed in opposite directions? (Hamilton) I need a moment of levity Seventeen seventy-six\n",
            "New York City\n",
            "Pardon me, are you Aaron Burr, sir? That depends, who's asking? Oh, sure, sir\n",
            "I'm Alexander Hamilton, I'm at your service, sir\n",
            "I have been looking for you I'm getting nervous Sir, I heard your name at Princeton\n",
            "I was seeking an accelerated course of study\n",
            "When I got sort of out of sorts with a buddy of yours\n",
            "I may have punched him it's a blur, sir\n",
            "He handles the financials? You punched the bursar? Yes, I wanted to do what you did\n",
            "Graduate in two, then join the revolution he looked at me like I was stupid I'm not stupid So how'd you do it, how'd you graduate so fast? It was my parent's dying wish before they passed You're an orphan, of course I'm an orphan\n",
            "God, I wish there was a war\n",
            "Then we could prove that we're worth more than anyone bargained for Can I buy you a drink?\n",
            "That would be nice While we're talking, let me offer you some free advice\n",
            "Talk less What? Smile more Ha Don't let them know what you're against or what you're for You can't be serious You wanna get ahead? Yes Fools who run their mouths off wind up dead Yo yo yo yo yo\n",
            "What time is it? Show time Like I said Show time, show time\n",
            "Yo, I'm John Lauren's in the place to be\n",
            "Two pints o' Sam Adams, but I'm workin' on three, uh\n",
            "Those redcoats don't want it with me\n",
            "'Cause I will pop chick-a pop these cops till I'm free Oui oui, mon ami, je m'appelle Lafayette\n",
            "The Lancelot of the revolutionary set\n",
            "I came from afar just to say bonsoir\n",
            "Tell the king casse-toi\n",
            "Who's the best, c'est moi Brrrah, brraaah I am Hercules Mulligan\n",
            "Up in it, lovin' it, yes I heard ya mother said come again Ay, lock up ya daughters and horses, of course\n",
            "It's hard to have intercourse over four sets of corsets (wow) No more sex, pour me another brew, son\n",
            "Let's raise a couple more to the revolution Well, if it ain't the prodigy of Princeton college Aaron Burr Give us a verse, drop some knowledge Good luck with that, you're takin' a stand\n",
            "You spit, I'm 'a sit\n",
            "We'll see where we land (boo) Burr, the revolution's imminent, what do you stall for? If you stand for nothing Burr, what'll you fall for? Oh, who are you oh, who are you oh, who are you?\n",
            "Oh, who is this kid, what's he gonna do? How does a bastard, orphan, son of a whore\n",
            "And a Scotsman, dropped in the middle of a forgotten spot in the Caribbean by providence impoverished,\n",
            "In squalor, grow up to be a hero and a scholar? The ten-dollar founding father without a father\n",
            "Got a lot farther by working a lot harder\n",
            "By being a lot smarter By being a self-starter\n",
            "By fourteen, they placed him in charge of a trading charter And every day while slaves were being slaughtered and carted away\n",
            "Across the waves, he struggled and kept his guard up\n",
            "Inside, he was longing for something to be a part of\n",
            "The brother was ready to beg, steal, borrow, or barter Then a hurricane came, and devastation reigned\n",
            "Our man saw his future drip, dripping down the drain\n",
            "Put a pencil to his temple, connected it to his brain\n",
            "And he wrote his first refrain, a testament to his pain Well, the word got around, they said, this kid is insane, man\n",
            "Took up a collection just to send him to the mainland\n",
            "Get your education, don't forget from whence you came\n",
            "And the world is gonna know your name\n",
            "What's your name, man? Alexander Hamilton\n",
            "My name is Alexander Hamilton\n",
            "And there's a million things I haven't done\n",
            "But just you wait, just you wait When he was six, a hurricane came, and devastation reigned\n",
            "His father left him and his mother destitute\n",
            "They called him Mister Hamilton\n",
            "And he responded by writing his first refrain, a testament to his power\n",
            "He said, with all my strength, let it be\n",
            "I'll write my second refrain, a testament to his fragility Hold on, let's get this straight Mister President, if we support Israel, we support Lebanon, we end the war, we're good\n",
            "I know that sounds crazy, but the more people say the name, the less likely it is that we get it Right, man? That's crazy talk, man\n",
            "But actually, it's\n",
            "\n",
            "[510 | 489.99] loss=0.02 avg=0.13\n",
            "[520 | 498.83] loss=0.05 avg=0.13\n",
            "[530 | 507.67] loss=0.02 avg=0.13\n",
            "[540 | 516.50] loss=0.01 avg=0.12\n",
            "[550 | 525.33] loss=0.06 avg=0.12\n",
            "[560 | 534.16] loss=0.03 avg=0.12\n",
            "[570 | 542.99] loss=0.03 avg=0.12\n",
            "[580 | 551.83] loss=0.01 avg=0.11\n",
            "[590 | 560.66] loss=0.03 avg=0.11\n",
            "[600 | 569.49] loss=0.01 avg=0.11\n",
            "[610 | 578.33] loss=0.01 avg=0.11\n",
            "[620 | 587.19] loss=0.02 avg=0.11\n",
            "[630 | 596.02] loss=0.02 avg=0.10\n",
            "[640 | 604.86] loss=0.03 avg=0.10\n",
            "[650 | 613.69] loss=0.04 avg=0.10\n",
            "[660 | 622.52] loss=0.02 avg=0.10\n",
            "[670 | 631.35] loss=0.02 avg=0.10\n",
            "[680 | 640.18] loss=0.01 avg=0.10\n",
            "[690 | 649.02] loss=0.03 avg=0.10\n",
            "[700 | 657.86] loss=0.00 avg=0.09\n",
            "[710 | 666.69] loss=0.01 avg=0.09\n",
            "[720 | 675.53] loss=0.01 avg=0.09\n",
            "[730 | 684.36] loss=0.01 avg=0.09\n",
            "[740 | 693.19] loss=0.01 avg=0.09\n",
            "[750 | 702.03] loss=0.03 avg=0.09\n",
            "[760 | 710.86] loss=0.01 avg=0.09\n",
            "[770 | 719.70] loss=0.04 avg=0.08\n",
            "[780 | 728.53] loss=0.04 avg=0.08\n",
            "[790 | 737.36] loss=0.02 avg=0.08\n",
            "[800 | 746.20] loss=0.02 avg=0.08\n",
            "[810 | 755.04] loss=0.01 avg=0.08\n",
            "[820 | 763.87] loss=0.04 avg=0.08\n",
            "[830 | 772.70] loss=0.04 avg=0.08\n",
            "[840 | 781.53] loss=0.02 avg=0.08\n",
            "[850 | 790.36] loss=0.01 avg=0.08\n",
            "[860 | 799.20] loss=0.03 avg=0.08\n",
            "[870 | 808.02] loss=0.02 avg=0.07\n",
            "[880 | 816.85] loss=0.02 avg=0.07\n",
            "[890 | 825.69] loss=0.01 avg=0.07\n",
            "[900 | 834.52] loss=0.03 avg=0.07\n",
            "[910 | 843.36] loss=0.08 avg=0.07\n",
            "[920 | 852.20] loss=0.04 avg=0.07\n",
            "[930 | 861.04] loss=0.03 avg=0.07\n",
            "[940 | 869.87] loss=0.01 avg=0.07\n",
            "[950 | 878.70] loss=0.02 avg=0.07\n",
            "[960 | 887.54] loss=0.01 avg=0.07\n",
            "[970 | 896.40] loss=0.02 avg=0.07\n",
            "[980 | 905.25] loss=0.03 avg=0.07\n",
            "[990 | 914.10] loss=0.03 avg=0.07\n",
            "[1000 | 922.93] loss=0.01 avg=0.06\n",
            "Saving checkpoint/lmm-1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            " just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot\n",
            "It's time to take a shot I dream of life without a monarchy\n",
            "The unrest in France will lead to onarchy?\n",
            "Onarchy how you say, how you say, anarchy?\n",
            "When I fight, I make the other side panicky\n",
            "With my, shot Yo, I'm a tailor's apprentice\n",
            "And I got y'all knuckleheads in loco parentis\n",
            "I'm joining the rebellion 'cause I know it's my chance\n",
            "To socially advance, instead of sewin' some pants\n",
            "I'm gonna take a shot But we'll never be truly free\n",
            "Until those in bondage have the same rights as you and me\n",
            "You and I. Do or die. Wait till I sally in\n",
            "On a stallion with the first black battalion\n",
            "Have another shot Geniuses, lower your voices\n",
            "You keep out of trouble and you double your choices\n",
            "I'm with you, but the situation is fraught\n",
            "You've got to be carefully taught\n",
            "If you talk, you're gonna get shot Burr, check what we got\n",
            "Mister Lafayette, hard rock like Lancelot\n",
            "I think your pants look hot\n",
            "Laurens, I like you a lot\n",
            "Let's hatch a plot blacker than the kettle callin' the pot\n",
            "What are the odds the gods would put us all in one spot\n",
            "Poppin' a squat on conventional wisdom, like it or not\n",
            "A bunch of revolutionary manumission abolitionists?\n",
            "Give me a position, show me where the ammunition is Oh, am I talkin' too loud?\n",
            "Sometimes I get over excited, shoot off at the mouth\n",
            "I never had a group of friends before\n",
            "I promise that I'll make y'all proud Let's get this guy in front of a crowd I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot Everybody sing\n",
            "Whoa, whoa, whoa\n",
            "Hey, whoa, whoa, whoa\n",
            "Ay, let 'em hear ya Let's go Whoa, whoa, whoa I said shout it to the rooftops\n",
            "Whoa, whoa, whoa said, to the rooftops\n",
            "Whoa, whoa, whoa come on Come on, let's go\n",
            "Rise up\n",
            "When you're living on your knees, you rise up\n",
            "Tell your brother that he's gotta rise up\n",
            "Tell your sister that she's gotta rise up When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up? Rise up\n",
            "I imagine death so much it feels more like a memory\n",
            "When's it gonna get me?\n",
            "In my sleep, seven feet ahead of me?\n",
            "If I see it comin', do I run or do I let it be?\n",
            "Is it like a beat without a melody?\n",
            "See, I never thought I'd live past twenty\n",
            "Where I come from some get half as many\n",
            "Ask anybody why we livin' fast and we laugh, reach for a flask\n",
            "We have to make this moment last, that's plenty Scratch that this is not a moment, it's the movement\n",
            "Where all the hungriest brothers with something to prove went?\n",
            "Foes oppose us, we take an honest stand\n",
            "We roll like Moses, claimin' our promised land\n",
            "And? If we win our independence?\n",
            "'Zat a guarantee of freedom for our descendants?\n",
            "Or will the blood we shed begin an endless cycle of vengeance and death with no defendants?\n",
            "I know the action in the street is excitin'\n",
            "But Jesus, between all the bleedin' 'n fightin'\n",
            "I've been readin' 'n writin'\n",
            "We need to handle our financial situation\n",
            "Are we a nation of states what's the state of our nation?\n",
            "I'm past patiently waitin' I'm passionatelymashin' every expectation\n",
            "Every action's an act of creation\n",
            "I'm laughin' in the face of casualties and sorrow\n",
            "For the first time, I'm thinkin' past tomorrow And I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot We're\n",
            "\n",
            "[1010 | 961.29] loss=0.01 avg=0.06\n",
            "[1020 | 970.15] loss=0.01 avg=0.06\n",
            "[1030 | 979.00] loss=0.03 avg=0.06\n",
            "[1040 | 987.83] loss=0.02 avg=0.06\n",
            "[1050 | 996.67] loss=0.01 avg=0.06\n",
            "[1060 | 1005.52] loss=0.02 avg=0.06\n",
            "[1070 | 1014.36] loss=0.06 avg=0.06\n",
            "[1080 | 1023.19] loss=0.02 avg=0.06\n",
            "[1090 | 1032.03] loss=0.02 avg=0.06\n",
            "[1100 | 1040.86] loss=0.03 avg=0.06\n",
            "[1110 | 1049.69] loss=0.01 avg=0.06\n",
            "[1120 | 1058.51] loss=0.02 avg=0.06\n",
            "[1130 | 1067.35] loss=0.02 avg=0.06\n",
            "[1140 | 1076.18] loss=0.01 avg=0.06\n",
            "[1150 | 1085.01] loss=0.01 avg=0.06\n",
            "[1160 | 1093.85] loss=0.01 avg=0.06\n",
            "[1170 | 1102.69] loss=0.03 avg=0.05\n",
            "[1180 | 1111.52] loss=0.02 avg=0.05\n",
            "[1190 | 1120.35] loss=0.01 avg=0.05\n",
            "[1200 | 1129.19] loss=0.03 avg=0.05\n",
            "[1210 | 1138.02] loss=0.01 avg=0.05\n",
            "[1220 | 1146.87] loss=0.01 avg=0.05\n",
            "[1230 | 1155.72] loss=0.01 avg=0.05\n",
            "[1240 | 1164.55] loss=0.04 avg=0.05\n",
            "[1250 | 1173.38] loss=0.02 avg=0.05\n",
            "[1260 | 1182.21] loss=0.07 avg=0.05\n",
            "[1270 | 1191.04] loss=0.02 avg=0.05\n",
            "[1280 | 1199.87] loss=0.01 avg=0.05\n",
            "[1290 | 1208.73] loss=0.02 avg=0.05\n",
            "[1300 | 1217.57] loss=0.01 avg=0.05\n",
            "[1310 | 1226.40] loss=0.02 avg=0.05\n",
            "[1320 | 1235.24] loss=0.01 avg=0.05\n",
            "[1330 | 1244.07] loss=0.02 avg=0.05\n",
            "[1340 | 1252.90] loss=0.02 avg=0.05\n",
            "[1350 | 1261.73] loss=0.01 avg=0.05\n",
            "[1360 | 1270.57] loss=0.02 avg=0.05\n",
            "[1370 | 1279.40] loss=0.02 avg=0.05\n",
            "[1380 | 1288.23] loss=0.02 avg=0.05\n",
            "[1390 | 1297.07] loss=0.01 avg=0.05\n",
            "[1400 | 1305.90] loss=0.04 avg=0.05\n",
            "[1410 | 1314.73] loss=0.04 avg=0.05\n",
            "[1420 | 1323.57] loss=0.03 avg=0.05\n",
            "[1430 | 1332.40] loss=0.03 avg=0.04\n",
            "[1440 | 1341.24] loss=0.02 avg=0.04\n",
            "[1450 | 1350.07] loss=0.00 avg=0.04\n",
            "[1460 | 1358.90] loss=0.01 avg=0.04\n",
            "[1470 | 1367.72] loss=0.01 avg=0.04\n",
            "[1480 | 1376.55] loss=0.02 avg=0.04\n",
            "[1490 | 1385.39] loss=0.01 avg=0.04\n",
            "[1500 | 1394.22] loss=0.01 avg=0.04\n",
            "Saving checkpoint/lmm-1/model-1500\n",
            "======== SAMPLE 1 ========\n",
            " brin' like Moses, claimin' our promised land\n",
            "And? If we don't reach a peace, that's alright\n",
            "'Cause we'll never be truly free\n",
            "Until those in bondage have the same rights as you and me\n",
            "You and I. Do or die. Wait till I sally in\n",
            "On a stallion with the first black battalion\n",
            "Have another shot Geniuses, lower your voices\n",
            "You keep out of trouble and you double your choices\n",
            "I'm with you, but the situation is fraught\n",
            "You've got to be carefully taught\n",
            "If you talk, you're gonna get shot Burr, check what we got\n",
            "Mister Lafayette, hard rock like Lancelot\n",
            "I think your pants look hot\n",
            "Laurens, I like you a lot\n",
            "Let's hatch a plot blacker than the kettle callin' the pot\n",
            "What are the odds the gods would put us all in one spot\n",
            "Poppin' a squat on conventional wisdom, like it or not\n",
            "A bunch of revolutionary manumission abolitionists?\n",
            "Give me a position, show me where the ammunition is Oh, am I talkin' too loud?\n",
            "Sometimes I get over excited, shoot off at the mouth\n",
            "I never had a group of friends before\n",
            "I promise that I'll make y'all proud Let's get this guy in front of a crowd I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot Everybody sing\n",
            "Whoa, whoa, whoa\n",
            "Hey, whoa, whoa, whoa\n",
            "Ay, let 'em hear ya Let's go Whoa, whoa, whoa I said shout it to the rooftops\n",
            "Whoa, whoa, whoa said, to the rooftops\n",
            "Whoa, whoa, whoa come on Come on, let's go\n",
            "Rise up\n",
            "When you're living on your knees, you rise up\n",
            "Tell your brother that he's gotta rise up\n",
            "Tell your sister that she's gotta rise up When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up?\n",
            "When are these colonies gonna rise up? Rise up\n",
            "I imagine death so much it feels more like a memory\n",
            "When's it gonna get me?\n",
            "In my sleep, seven feet ahead of me?\n",
            "If I see it comin', do I run or do I let it be?\n",
            "Is it like a beat without a melody?\n",
            "See, I never thought I'd live past twenty\n",
            "Where I come from some get half as many\n",
            "Ask anybody why we livin' fast and we laugh, reach for a flask\n",
            "We have to make this moment last, that's plenty Scratch that this is not a moment, it's the movement\n",
            "Where all the hungriest brothers with something to prove went?\n",
            "Foes oppose us, we take an honest stand\n",
            "We roll like Moses, claimin' our promised land\n",
            "And? If we win our independence?\n",
            "'Zat a guarantee of freedom for our descendants?\n",
            "Or will the blood we shed begin an endless cycle of vengeance and death with no defendants?\n",
            "I know the action in the street is excitin'\n",
            "But Jesus, between all the bleedin' 'n fightin'\n",
            "I've been readin' 'n writin'\n",
            "We need to handle our financial situation\n",
            "Are we a nation of states what's the state of our nation?\n",
            "I'm past patiently waitin' I'm passionatelymashin' every expectation\n",
            "Every action's an act of creation\n",
            "I'm laughin' in the face of casualties and sorrow\n",
            "For the first time, I'm thinkin' past tomorrow And I am not throwing away my shot\n",
            "I am not throwing away my shot\n",
            "Hey yo, I'm just like my country\n",
            "I'm young, scrappy and hungry\n",
            "And I'm not throwing away my shot We're gonna rise up (time to take a shot)\n",
            "We're gonna rise up (time to take a shot)\n",
            "We're gonna, rise up, rise up It's time to take a shot\n",
            "Rise up, rise up, it's time to take a shot\n",
            "Rise up, it's time to take a shot\n",
            "Rise up, take a shot, shot, shot\n",
            "It's time to take a shot, time to take a shot\n",
            "And I am not throwing away my shot\n",
            "Not throwing away my shot Theodosia writes me a letter everyday\n",
            "I'm keeping the bed warm while her husband is away\n",
            "He's on the British side in Georgia\n",
            "He's trying to keep the colonies in line\n",
            "\n",
            "\n",
            "[1510 | 1430.71] loss=0.02 avg=0.04\n",
            "[1520 | 1439.55] loss=0.02 avg=0.04\n",
            "[1530 | 1448.38] loss=0.02 avg=0.04\n",
            "[1540 | 1457.21] loss=0.01 avg=0.04\n",
            "[1550 | 1466.05] loss=0.04 avg=0.04\n",
            "[1560 | 1474.88] loss=0.01 avg=0.04\n",
            "[1570 | 1483.71] loss=0.01 avg=0.04\n",
            "[1580 | 1492.55] loss=0.02 avg=0.04\n",
            "[1590 | 1501.38] loss=0.03 avg=0.04\n",
            "[1600 | 1510.22] loss=0.01 avg=0.04\n",
            "[1610 | 1519.07] loss=0.03 avg=0.04\n",
            "[1620 | 1527.92] loss=0.01 avg=0.04\n",
            "[1630 | 1536.75] loss=0.04 avg=0.04\n",
            "[1640 | 1545.58] loss=0.03 avg=0.04\n",
            "[1650 | 1554.43] loss=0.02 avg=0.04\n",
            "[1660 | 1563.26] loss=0.02 avg=0.04\n",
            "[1670 | 1572.09] loss=0.06 avg=0.04\n",
            "[1680 | 1580.93] loss=0.04 avg=0.04\n",
            "[1690 | 1589.76] loss=0.01 avg=0.04\n",
            "[1700 | 1598.59] loss=0.02 avg=0.04\n",
            "[1710 | 1607.42] loss=0.03 avg=0.04\n",
            "[1720 | 1616.25] loss=0.01 avg=0.04\n",
            "[1730 | 1625.09] loss=0.03 avg=0.04\n",
            "[1740 | 1633.93] loss=0.03 avg=0.04\n",
            "[1750 | 1642.77] loss=0.02 avg=0.04\n",
            "[1760 | 1651.60] loss=0.03 avg=0.04\n",
            "[1770 | 1660.44] loss=0.01 avg=0.04\n",
            "[1780 | 1669.26] loss=0.02 avg=0.04\n",
            "[1790 | 1678.09] loss=0.02 avg=0.04\n",
            "[1800 | 1686.92] loss=0.02 avg=0.04\n",
            "[1810 | 1695.75] loss=0.04 avg=0.04\n",
            "[1820 | 1704.58] loss=0.02 avg=0.04\n",
            "[1830 | 1713.42] loss=0.02 avg=0.04\n",
            "[1840 | 1722.24] loss=0.00 avg=0.04\n",
            "[1850 | 1731.07] loss=0.01 avg=0.03\n",
            "[1860 | 1739.92] loss=0.01 avg=0.03\n",
            "[1870 | 1748.75] loss=0.00 avg=0.03\n",
            "[1880 | 1757.59] loss=0.01 avg=0.03\n",
            "[1890 | 1766.43] loss=0.03 avg=0.03\n",
            "[1900 | 1775.27] loss=0.01 avg=0.03\n",
            "[1910 | 1784.10] loss=0.01 avg=0.03\n",
            "[1920 | 1792.93] loss=0.00 avg=0.03\n",
            "[1930 | 1801.76] loss=0.01 avg=0.03\n",
            "[1940 | 1810.59] loss=0.09 avg=0.03\n",
            "[1950 | 1819.42] loss=0.02 avg=0.03\n",
            "[1960 | 1828.28] loss=0.01 avg=0.03\n",
            "[1970 | 1837.12] loss=0.00 avg=0.03\n",
            "[1980 | 1845.94] loss=0.01 avg=0.03\n",
            "[1990 | 1854.78] loss=0.02 avg=0.03\n",
            "[2000 | 1863.61] loss=0.02 avg=0.03\n",
            "Saving checkpoint/lmm-1/model-2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='rap-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run6')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxL77nvAMAX",
        "outputId": "806f6024-3a21-4b5d-86c5-8055c5e8ffee"
      },
      "source": [
        "#import tensorflow as tf\n",
        "sess = gpt2.start_tf_sess()\n",
        "#tf.reset_default_graph()\n",
        "gpt2.load_gpt2(sess, run_name='run6')\n",
        "#gpt2.generate(sess, run_name='rap-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run6/model-500\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run6/model-500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "W8y_mrKBxzEj",
        "outputId": "4250fef9-321d-41f6-8ab3-1df96ab4e358"
      },
      "source": [
        "with open((\"dataset/\" + file_name), 'r') as f:\n",
        "  dset = f.read()\n",
        "\n",
        "import collections, nltk\n",
        "# we first tokenize the text corpus\n",
        "nltk.download('punkt')\n",
        "tokens = nltk.word_tokenize(dset)\n",
        "\n",
        "def unigram(tokens):\n",
        "  model = collections.defaultdict(lambda: 0.1)\n",
        "  #print(type(model))\n",
        "  for f in tokens:\n",
        "    try:\n",
        "      model[f] += 1\n",
        "    except KeyError:\n",
        "      model [f] = 1\n",
        "      continue\n",
        "  N = float(sum(model.values()))\n",
        "  for word in model:\n",
        "    model[word] = model[word]/N\n",
        "  return model\n",
        "\n",
        "#computes perplexity of the unigram model on a testset    \n",
        "def perplexity(testset, model):\n",
        "  testset = testset.split()\n",
        "  perplexity = 1\n",
        "  N = 0\n",
        "  for word in testset:\n",
        "    N += 1\n",
        "    perplexity = perplexity * (1/model[word])\n",
        "  perplexity = pow(perplexity, 1/float(N)) \n",
        "  return perplexity\n",
        "\n",
        "model2 = unigram(tokens)\n",
        "print(perplexity(\"nothing\", model2))\n",
        "\n",
        "\"\"\"\n",
        "ppls = []\n",
        "\n",
        "for i in range(40):\n",
        "  snippet1 = gpt2.generate(sess, run_name=\"rap-1\", return_as_list=True)[0]\n",
        "  snippet1 = snippet1.split(\"\\n\")[0]\n",
        "  print(snippet1)\n",
        "  ppl = perplexity(snippet1, model2)\n",
        "  print(\"i:\", i)\n",
        "  print(ppl)\n",
        "  ppls.append(ppl)\n",
        "  print(\"avg:\", sum(ppls)/(len(ppls) + 1))\n",
        "\n",
        "print(sum(ppls)/len(ppls))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2011.9392789353158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nppls = []\\n\\nfor i in range(40):\\n  snippet1 = gpt2.generate(sess, run_name=\"rap-1\", return_as_list=True)[0]\\n  snippet1 = snippet1.split(\"\\n\")[0]\\n  print(snippet1)\\n  ppl = perplexity(snippet1, model2)\\n  print(\"i:\", i)\\n  print(ppl)\\n  ppls.append(ppl)\\n  print(\"avg:\", sum(ppls)/(len(ppls) + 1))\\n\\nprint(sum(ppls)/len(ppls))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "GGXRnYJbc-EY",
        "outputId": "79d95432-a9ac-4326-eabc-b16ba90e34d7"
      },
      "source": [
        "# next word prediction\n",
        "import random\n",
        "\n",
        "\n",
        "def rm_from_list(somelist):\n",
        "    badlines = [\"\", \"\\n\"]\n",
        "    for i in badlines:\n",
        "      somelist = [x for x in somelist if x not in badlines]\n",
        "    return somelist\n",
        "    \n",
        "with open((\"dataset/\" + file_name), 'r') as f:\n",
        "  dset = f.read()\n",
        "dset = rm_from_list(dset.split(\"\\n\"))\n",
        "\n",
        "num_correct = 0\n",
        "\n",
        "for i in range(50):\n",
        "  random_line = dset[random.randint(0, len(dset))]\n",
        "  words = random_line.split(\" \")\n",
        "  split_at = int(len(words)/2)\n",
        "  #print(words)\n",
        "  prevwords = \" \".join(words[:split_at])\n",
        "  correct_word = words[split_at]\n",
        "  print(\"prevwords is:\", prevwords, \"- correct_word is:\", correct_word)\n",
        "\n",
        "  snippet1 = gpt2.generate(sess, run_name=\"run6\", return_as_list=True, prefix=prevwords)[0].split(\"\\n\")\n",
        "  #print(snippet1)\n",
        "  #print(snippet1[:1])\n",
        "  if snippet1[0] == prevwords:\n",
        "    print(\"thought end of line\")\n",
        "  else:\n",
        "    nextword = snippet1[0].replace(prevwords, \"\").split(\" \")\n",
        "    #print(\"nw\", nextword)\n",
        "    if nextword[0] == \" \" or nextword[0] == \"\":\n",
        "      nextword = nextword[1]\n",
        "    else:\n",
        "      nextword = nextword[0]\n",
        "    #print(\"nextword is:\", nextword)\n",
        "    print(\"WE PREDICTED THE CORRECT WORD: \", nextword == correct_word)\n",
        "    if nextword == correct_word:\n",
        "      num_correct += 1\n",
        "    print(num_correct/(i+1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prevwords is:     - correct_word is: R,\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.0\n",
            "prevwords is:     I - correct_word is: put\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.0\n",
            "prevwords is:      - correct_word is: \n",
            "WE PREDICTED THE CORRECT WORD:  True\n",
            "0.3333333333333333\n",
            "prevwords is:     - correct_word is: What\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.25\n",
            "prevwords is:       And - correct_word is: he'd\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.2\n",
            "prevwords is:     The lion and - correct_word is: the\n",
            "WE PREDICTED THE CORRECT WORD:  True\n",
            "0.3333333333333333\n",
            "prevwords is:     - correct_word is: \n",
            "WE PREDICTED THE CORRECT WORD:  True\n",
            "0.42857142857142855\n",
            "prevwords is:      - correct_word is: \n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.375\n",
            "prevwords is:     - correct_word is: \n",
            "WE PREDICTED THE CORRECT WORD:  True\n",
            "0.4444444444444444\n",
            "prevwords is:     He - correct_word is: stuck\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.4\n",
            "prevwords is: DANTY - correct_word is: BABY\n",
            "WE PREDICTED THE CORRECT WORD:  False\n",
            "0.36363636363636365\n",
            "prevwords is:     And - correct_word is: feed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a334c4c7e676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prevwords is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"- correct_word is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0msnippet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"run6\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_as_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprevwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0;31m#print(snippet1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m#print(snippet1[:1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             out = sess.run(output, feed_dict={\n\u001b[0;32m--> 471\u001b[0;31m                     \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontext_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                 })\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A86UivzvzG8f"
      },
      "source": [
        "snippet1 = gpt2.generate(sess, run_name=\"rap-1\", return_as_list=True, temperature=0.5)[0].split(\"\\n\")\n",
        "\n",
        "def rm_from_list(somelist):\n",
        "    badlines = [\"\", \"\\n\"]\n",
        "    for i in badlines:\n",
        "      somelist = [x for x in somelist if x not in badlines]\n",
        "    return somelist\n",
        "    \n",
        "with open((\"dataset/\" + file_name), 'r') as f:\n",
        "  dset = f.read()\n",
        "dset = rm_from_list(dset.split(\"\\n\"))\n",
        "snippet1 = rm_from_list(snippet1)\n",
        "\n",
        "#print(dset)\n",
        "#print(snippet1)\n",
        "\n",
        "def line_overlap(snippet):\n",
        "  snippet = rm_from_list(snippet)\n",
        "  overlapnum = len(list(set(dset) & set(snippet)))\n",
        "  lesser = min(len(dset), len(snippet))\n",
        "  return overlapnum/lesser\n",
        "\n",
        "\n",
        "def wordFreq(snippet):\n",
        "  from collections import Counter\n",
        "  ds = \"\\n\".join(dset).split(\" \")\n",
        "  sp = \"\\n\".join(snippet).split(\" \")\n",
        "  c1 = Counter(ds).most_common(20)\n",
        "  c2 = Counter(sp).most_common(20)\n",
        "  cw1 = [i[0] for i in c1]\n",
        "  cw2 = [i[0] for i in c2]\n",
        "  return len(list(set(cw1) & set(cw2)))/20\n",
        "\n",
        "print(line_overlap(snippet1))\n",
        "print(wordFreq(snippet1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N"
      },
      "source": [
        "gpt2.generate(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=1,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20,\n",
        "                      run_name=\"run6\"\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD"
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "# run if errors\n",
        "#!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}